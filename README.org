#+begin_center
*Vulkan is an API for graphics and compute hardware*
不仅仅用于图形渲染，还可用于计算
#+end_center

* Mac 下载安装 Vulkan SDK:
1. 从 lunarg 下载 [[https://vulkan.lunarg.com/home/welcome]] Vulkan SDK 的 MacOS 版本， Mac/iOS 下的 Vulkan 并非原生实现，而是通过 *MoltenVK* [[https://github.com/KhronosGroup/MoltenVK]]  作为中间层调用 Metal 来实现的。
2. 下载 Vulkan SDK 后，将它解压到一个合适的位置。 *Vulkan SDK 的 MacOS 版，已经内置了编译好的 MoltenVK。*
3. 然后在 ~/.bash_profile 文件中设置下面这些环境变变量。详见 [[https://vulkan.lunarg.com/doc/sdk/1.1.92.1/mac/getting_started.html]]
   #+begin_src sh
# 把 VULKAN_SDK 设置为 SDK 解压后里面 macOS 目录的地址。
export VULKAN_SDK=/Users/monty/STUDY/vulkansdk-macos-1.1.101.0/macOS

export VK_ICD_FILENAMES=$VULKAN_SDK/etc/vulkan/icd.d/MoltenVK_icd.json
export VK_LAYER_PATH=$VULKAN_SDK/etc/vulkan/explicit_layer.d

export DYLD_LIBRARY_PATH=$VULKAN_SDK/lib:$DYLD_LIBRARY_PATHH
export PATH=$PATH:$VULKAN_SDK/bin
   #+end_src
   - 运行 $VULKAN_SDK/bin 目录里的命令行程序 vulkaninfo 确认配置正确
   #+begin_src sh
monty$  cd $VULKAN_SDK/bin
monty$  vulkaninfo
   #+end_src


** 安装 GLFW
Vulkan 是一个平台无关的图形 API，它没有包含任何用于创建窗口的功能。为了跨平台和避免陷入 Win32 的窗口细节中去，我们使用 *GLFW* [[https://github.com/glfw/glfw]] 库来完成窗口相关操作，GLFW 库支持 Windows，Linux 和 MacOS。当然，还有其它一些库可以完成类似功能，比如 SDL。但除了窗口相关处理，GLFW 库对于 Vulkan 的使用还有其它一些优点。读者可以再 GLFW 的官方网站上免费下载到最新版本的 GLFW 库。

#+begin_src sh
$ brew install glfw3   #/usr/local/Cellar/ 目录下会多出来一个 glfw 的文件夹，相关的文件都在这个里面。
#+end_src


** 安装 GLM

Vulkan 没有包含线性代数库，我们需要自己找一个。GLM 就是一个我们需要的线性代数库，它经常和 Vulkan 和 OpenGL 一块使用。GLM 是一个只有头文件的库，我们只需要下载它的最新版，然后将它放在一个合适的位置，就可以通过包含头文件的方式使用它。
#+begin_src sh
brew install glm
#+end_src

** 在 CMakeLists.txt 文件里 设置 GLFW 和 VULKAN 头文件和链接库的路径：
参考这里设置 [[https://zhuanlan.zhihu.com/p/45528705][CMakeLists.txt]]

#+begin_src sh

# 通过$ENV{VULKAN_SDK} 引用在 ~/.bash_profile 里设置的环境变量 VULKAN_SDK
INCLUDE_DIRECTORIES("/usr/local/include")   #brew 安装头文件的目录 /usr/local/include, 包括 GLFW 和 GLM 的头文件
INCLUDE_DIRECTORIES("$ENV{VULKAN_SDK}/include")   # VULKAN 的头文件

LINK_LIBRARIES("/usr/local/lib/libglfw.3.3.dylib")  # GLFW 的动态链接库。brew 安装链接库的目录 /usr/local/lib
LINK_LIBRARIES("$ENV{VULKAN_SDK}/lib/libvulkan.1.dylib")  # vulkan 的动态链接库
LINK_LIBRARIES("$ENV{VULKAN_SDK}/lib/libvulkan.1.1.101.dylib")  #

#+end_src



** 编译运行 cmake build
至此, 你已经完成了基本项目的构建, 可以随意修改代码, 只要运行
#+begin_src sh
mkdir build   # 如果没有 build 目录，就先创建一个。
cd build

cmake ..  #生成 Makefile

make   #编译

#+end_src
就可以生成可执行文件了.

** Xcode 使用 Vulkan SDK 的开发环境配置，可以参考 *Vulkan Tutorial* 这本书中的设置 [[https://vulkan-tutorial.com/Development_environment#page_MacOS ]]


* Vulkan vs OpenGL
在有一些场景中，我们将观察到，OpenGL 和 Vulkan 之间在性能方面没有任何差别。 如果不需要多线程化，或应用不是 *CPU 密集型* （渲染的场景不太复杂），使用 OpenGL 即可，而且使用 Vulkan  不会实现性能提升 （但可能会 *降低功耗， 这对移动设备至关重要* ）。 但如果我们想最大限度地发挥图形硬件的功能，Vulkan 将是最佳选择。



* Vulkan的大体流程：
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800   #+ATTR_ORG: :width 800
[[file:vulkan_program_flow.jpg]]



* 初始化过程涉及的对象

** 选择设备：实例Instance -> 物理设备PhysicalDevice -> 逻辑设备Device
*** 创建实例前，先确认所有想要的实例层扩展和验证是否都存在:
- 3个实例层扩展 VK_KHR_surface, VK_MVK_macos_surface,  VK_EXT_debug_utils
- 1个实例层验证 VK_LAYER_KHRONOS_validation

扩展有2类，实例层扩展和逻辑设备扩展。现在推荐使用实例层验证，逻辑设备层验证不推荐使用了。
- 实例扩展：就是创建实例时将要请求启用的扩展
  - vkEnumerateInstanceExtensionProperties(nullptr, &extensionCount, extensions.data()) 创建实例前，先获取所有可以用于实例的扩展， 确认所有想要的扩展都是存在的。 然后再在VkInstanceCreateInfo中请求启用。
  - 如果在macOS、Win系统上，使用glfwGetRequiredInstanceExtensions(&glfwExtensionCount) 可以方便的返回实例层用来创建surface所需要的扩展列表，不但有基础的VK_KHR_surface扩展， 还有针对特定操作系统的扩展，macOS是 VK_MVK_macos_surface

- 实例层验证：vkEnumerateInstanceLayerProperties(&layerCount, availableLayers.data()); 在创建实例前，获得所有可用于实例层的验证, 确认所有想要的验证都是存在的， 然后再在VkInstanceCreateInfo中请求启用。
  - 实例层验证的作用：函数调用传递的参数是否符合规范、对象的创建和销毁是否有内存泄露、线程是否安全、记录每个函数调用并在标准设备上输出、分析函数调用和重播
  - 最常用的实例层验证是：VK_LAYER_KHRONOS_validation，它是一个大的验证层集合，系统把所有标准常用的验证层都融合在一起。 它默认在终端输出所有验证层的调试信息。 启用实例扩展 VK_EXT_debug_utils后， 定义一个回调函数，只输出我们感兴趣的信息。
    
- 逻辑设备扩展：就是在创建逻辑设备时请求启用的扩展。经常在选择合适的物理设备时，使用vkEnumerateDeviceExtensionProperties(gpu, nullptr, &extensionCount, availableExtensions.data())  在创建逻辑设备前，获取莫个物理设备的所有 *逻辑设备扩展* ： 确认我们想在逻辑设备中使用的扩展都是存在的， 比如检查是否支持交换链扩展 VK_KHR_swapchain， 然后再在VkDeviceCreateInfo中请求启用。
    
#+begin_src c++
vkEnumerateInstanceExtensionProperties(nullptr, &extensionCount, extensions.data());
glfwGetRequiredInstanceExtensions(&glfwExtensionCount); // 如果在macOS、Win系统上，这个方法可以方便的返回实例层用来创建surface所需要的扩展列表，不但有基础的VK_KHR_surface扩展， 还有针对特定操作系统的扩展，macOS是 VK_MVK_macos_surface
vkEnumerateInstanceLayerProperties(&layerCount, availableLayers.data()); //  在创建实例前，获得所有可用于实例层的验证, 确认所有想要的验证都是存在的， 然后再在VkInstanceCreateInfo中请求启用。
#+end_src
*** 创建一个 VkInstance 对象
- 在instance_createInfo中启用3个实例层扩展、1个实例层验证；
- 把pNext设为debugmsg_CreateInfo， 让2个自定义函数vkCreateDebugUtilsMessengerEXT 和 vkDestroyDebugUtilsMessengerEXT 可以共用一个VkDebugUtilsMessengerEXT实例

物理设备可以简单的和GPU硬件对应起来。例如集成显卡对应一个物理设备，独立显卡RTX2080TI对应一个物理设备。一台电脑上经常有多个GPU硬件，例如集成显卡Intel(R) HD Graphics 630、独立显卡RTX2080TI、计算卡NVIDIA P106。

#+begin_src c++
// 实例层验证VK_LAYER_KHRONOS_validation默认在终端输出所有验证信息。可以启用实例扩展VK_EXT_debug_utils，然后自定义一个回调函数，就可只输出我们感兴趣的信息。
instance_createInfo.ppEnabledExtensionNames = extensions.data(); // 包含3个扩展 VK_KHR_surface, VK_MVK_macos_surface,  VK_EXT_debug_utils
instance_createInfo.ppEnabledLayerNames = validationLayers.data(); // VK_LAYER_KHRONOS_validation, 它是一个大的验证层集合，系统把所有标准常用的验证层，都融合在一起。

populateDebugMessengerCreateInfo(debugmsg_CreateInfo);  // 设置接收消息的回调函数pfnUserCallback，要输出的信息类型：warning, error...触发回调的事件类型：validation, performance...
instance_createInfo.pNext = (VkDebugUtilsMessengerCreateInfoEXT*) &debugmsg_CreateInfo; // 把pNext设为debugmsg_CreateInfo，vkCreateDebugUtilsMessengerEXT和 vkDestroyDebugUtilsMessengerEXT 就可以共用下面的debugMessenger实例。

vkCreateInstance(&createInfo, nullptr, &instance) // 创建实例，实例层扩展和验证，要在VkInstanceCreateInfo实例创建信息中请求启用。
#+end_src

*** 创建VkDebugUtilsMessengerEXT实例
- 创建函数vkCreateDebugUtilsMessengerEXT 和 vkDestroyDebugUtilsMessengerEXT 共用的VkDebugUtilsMessengerEXT实例
#+begin_src c++
VkDebugUtilsMessengerEXT debugMessenger;
VkDebugUtilsMessengerCreateInfoEXT debugmsg_CreateInfo;

// populateDebugMessengerCreateInfo
debugmsg_CreateInfo.messageSeverity =  VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT; //要输出的信息类型：warning, error...
debugmsg_CreateInfo.messageType =  VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT; // 触发回调的事件类型：validation, performance...
debugmsg_CreateInfo.pfnUserCallback = debugCallback; //  设置接收消息的回调函数

vkCreateDebugUtilsMessengerEXT(instance, &debugmsg_CreateInfo, nullptr, &debugMessenger); // 生成VkDebugUtilsMessengerEXT的实例。
#+end_src

*** 创建窗口surface, 需要在instance被创建后立即被创建，因为这个surface会作为下面选择物理设备是否合适的一个条件
- 窗口 *VkSurfaceKHR* ： 后缀 KHR 意思是这些对象是 Vulkan 扩展的一部分。除非你不想显示图形(比如你只想离屏渲染)，不然你还是需要创建一个窗口来显示的。Vulkan API 是完全的平台不可知论者，这就是我们需要用标准化 WSI（窗口系统接口）扩展与窗口管理器交互的原因。Surface 是对可渲染窗口的跨平台抽象，一般通过提供一个本地窗口句柄的方式来实例化，例如在 Windows 上提供的句柄是 HWND。
#+begin_src c++
// vkGetPhysicalDeviceSurfaceSupportKHR(gpu, i, surface, &presentSupport); 判断某个gpu、的某个队列家族、是否支持在这个surface显示present图像。
glfwCreateWindowSurface(instance, window, nullptr, &surface); // 创建surface
#+end_src

*** 选择物理设备（VkPhysicalDevice）：队列支持绘制和显示 + 逻辑设备支持交换链扩展VK_KHR_swapchain
- 枚举GPU硬件，选取一个或多个物理设备。一个VkInstance可有多个VkPhysicalDevice， 一个VkPhysicalDevice可创建多个逻辑设备VkDevice。跨GPU的调用还未实现。
- 队列簇QueueFamily，如：RTX2080TI显卡有16个队列用于绘图、8个队列用于计算、1个队列用于CPU和GPU间的数据传输。Vulkan将这些专有的功能队列称之为簇， 每一簇里面又分别有不同数量的队列。
- queue的职责是收集命令（命令缓冲区）并将其分派给gpu执行。 队列从QueueFamily中分配，Vulkan中的操作最终提交到Queue来异步执行的。共有4种队列
  - VK_QUEUE_GRAPHICS_BIT：图形
  - VK_QUEUE_COMPUTE_BIT：计算
  - VK_QUEUE_TRANSFER_BIT：传送（复制等内存操作）
  - VK_QUEUE_SPARSE_BINDING_BIT：内存绑定操作，用于更新稀疏资源。
    - 在矩阵中，若数值为0的元素远远多于非0元素，并且非0元素分布没有规律时，则称该矩阵为 *稀疏矩阵* ；与之相反，若非0元素占大多数时，则称该矩阵为 *稠密矩阵* 。
    - *稀疏内存* 是一项特殊功能，可让您存储大型图像资源；图像在内存中的存储容量远大于实际的存储容量。 这种技术是将图像分解为图块，并仅加载适合应用程序逻辑的图块。

- 选取合适的物理设备， 主要是看某个gup的队列簇QueueFamily是否满足要求，比如，为了要在窗口中显示图片， *队列支持绘制和显示 + 逻辑设备也要支持交换链扩展*
  - 需要注意的是，支持绘制和呈现的队列不一定是同一个。
  - *VK_QUEUE_GRAPHICS_BIT* 队列支持绘制，也就是：queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT
  - *surface* 队列支持图片显示：vkGetPhysicalDeviceSurfaceSupportKHR(gpu, i, surface, &presentSupport); 判断某个gpu、的某个队列家族、是否支持在这个surface显示present图像。
  - *VK_KHR_swapchain* 逻辑设备支持交换链扩展： 通过vkEnumerateDeviceExtensionProperties(gpu, nullptr, &extensionCount, availableExtensions.data())查询逻辑设备是否支持交换链扩展。

#+begin_src c++
vkEnumeratePhysicalDevices(instance, &deviceCount, gpus.data()); // 枚举GPU
{ // isDeviceSuitable
    {
        vkGetPhysicalDeviceProperties(gup, &gpuProperties); // 查询物理设备的属性：支持的Vulkan API版本、设备名称和类型（集成或专用/独立GPU）、厂商ID和限制。
        vkGetPhysicalDeviceFeatures(gpu, &gpuFeatures); // 获取物理设备的可选特性，如：是否支持geometryShaderh或者tessellationShader，纹理压缩、64位浮点数和多视口渲染
        if(gpuProperties.deviceType == VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU && gpuFeatures.geometryShader);  // 是否独立显卡和支持几何着色器

        // findQueueFamilies,  为了要在窗口中显示图片，队列就要支持绘制和呈现，也就是：VK_QUEUE_GRAPHICS_BIT  和 vkGetPhysicalDeviceSurfaceSupportKHR 检查surface是否支持图片显示。
        vkGetPhysicalDeviceQueueFamilyProperties(gpu, &queueFamilyCount, queueFamilies.data());  //获取物理设备的 队列属性
        if (queueFamily.queueCount > 0 && queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT);  // 现在我们将只查找支持图形命令的队列
        vkGetPhysicalDeviceSurfaceSupportKHR(gpu, i, surface, &presentSupport); // 判断某个gpu、某个队列家族、是否支持在这个surface显示present图像。

        //checkDeviceExtensionSupport 获取莫个物理设备的所有 *逻辑设备扩展* 确认支持交换链扩展VK_KHR_swapchain， 要显示图片，这个逻辑实例扩展一定是要的。
        vkEnumerateDeviceExtensionProperties(gpu, nullptr, &extensionCount, availableExtensions.data());

    }
}

#+end_src

*** 创建逻辑设备 VkDevice
- 为什么需要创建逻辑设备? 因为大多数时候我们不需要物理设备的全部功能，在不同的场景， 只会开启其中的部分功能。比如挖矿、视频解压等情况就不需要渲染簇； 要画面显示的应用就不需要Compute簇等等。

#+begin_src c++
queueCreateInfo.queueFamilyIndex = selected_queuefamily_index;  // 想要启用的队列家族索引（通过它创建队列）, 队列在设备创建时会一同自动创建。
queueCreateInfo.queueCount = 1; //我们希望在特定队列家族中启用的队列数量
device_createInfo.pQueueCreateInfos = queueCreateInfos.data();
createInfo.pEnabledFeatures = &deviceFeatures; // 希望启用的 vkGetPhysicalDeviceFeatures 特性， 比如几何着色器。

device_createInfo.ppEnabledExtensionNames = deviceExtensions.data(); //启用逻辑设备交换链扩展VK_KHR_swapchain，显示图片这个一定要。deviceExtensions = { VK_KHR_SWAPCHAIN_EXTENSION_NAME }
vkCreateDevice(gpu, &device_createInfo, nullptr, &device);  // 队列随着逻辑设备的创建而自动创建

vkGetDeviceQueue(device, indices.graphicsFamily.value(), 0, &graphicsQueue); // 从队列家族获取队列句柄，保存在graphicsQueue。因为我们只创建一个队列，用索引0即可。
vkGetDeviceQueue(device, indices.presentFamily.value(), 0, &presentQueue

#+end_src


** 显示： 窗口surface -> 交换链Swapchain -> 图像视图ImageView
*** 获取surface信息和创建Swapchain
- 交换链 *VkSwapchainKHR* ：Vulkan 中没有 *默认帧缓冲区 default framebuffer* 的概念。交换链确保当窗口系统在显示一个图像时，应用程序可以准备下一个图像， 保证 image 完全渲染完毕后才能进行显示十分重要。每次我们想绘制一帧时， 我们请求交换链提供给我们一个用于渲染的 image，当这一帧完成绘制后，这个 image 返回到交换链，准备在某个时刻被屏幕消费，呈现到屏幕上。
  
- vertical blank Interval vblank 垂直同步/垂直空白间隙： 我们通常收看的电视图象是由电子枪发射的电子串高速轰击显象管上的荧光物质而产生的，电子串按 从左至右， 从上至下的方式扫 描整个屏幕， 速度十分快，所以我们 的眼睛 感觉不到，当电子枪的扫描位置从左上角达到右下角时，必须由右下角回到下一 帧的左上角，以进行下一 张画面的显示。 而电子束的移动是需要时间的, 从右下角回到左上角所花费的时间就是垂直空白间隙。
  - vblank 垂直同步: 现在的显示器一般都支持双缓冲，一个由GPU写入，一个由显示器读取，到了时间再对换。详细的过程是： 当显示器绘制完A-buffer中的像素后（即绘制完第n+1帧），就会去读取B-buffer（GPU已经完成 写入的 第n+2帧）， 而GPU则转到这个被显示器已经读完的A-buffer，向其中写入第n+3帧的像素信息。有一种情况可能发生，在不严格规定时间间隙的情况下，GPU和显示器可能同时操作同一个buffer，就会导致 *画面的撕裂screen tearing* 。 显示器绘制 第n+1帧 到一半，buffer里 突然出现了第n+2帧的信息，造成显示器上的内容一半是第n+1帧，另一半是第n+2帧的，如果约定在vertical blank期间对 换buffer， 那么就能避免这个问题。 这个约定 就称为“垂直同步”。 因此，垂直同步不会增加GPU的负载， 但是会减少单位时间内画面的帧数， 因为即使 GPU渲染完了一帧， 必须要等待vertical blank， 才能将像素信息写入另一个buffer。
    - 垂直同步的副作用 *「卡顿」 「画面延迟」* ：目前还有很多显示器刷新率是 60Hz，也就是每秒钟要显示 60 张画面，如果显卡每秒产生 120 张画面， 而显示器每秒只读取 60 张，这会出现什么问题呢？ 显示器提取画面的时候会从上 到下一行一 行（逐行扫描）把画面显示出来，本来要 1/60 秒才能显示完， 然而显示了一半（1/120 秒）下一张画面就塞进来了。这时候显示器并不会停止工作，而是囫囵吞枣地把上一张画面的一半与下一张画面都显示出来。 由于 两张画面不一样，结果 就是上面 半截是第一张画面，下面半截是第二张画面，也就是所谓的 *画面撕裂* 。然而打开垂直同步又会引发一个问题。 如果跑步健将 博尔牛寺第 0 秒在起跑线上，第1/60秒就跑到了终点，那每秒渲染 60 张画面就完全看不到他中间的跑步过程！ 一开始就 直接跑完。这就是所谓的 *「卡顿」* ，画面并不连贯。 于是你会发现 不少游戏 下面还有一个「双重缓冲」的开关，也就是多开设一个缓冲区。显卡依旧每秒渲染 120 张画面， 第一张存在 缓冲区1， 第二张存在缓冲区2。 显示器来读取画 面的时候按 顺序先从缓冲区 1 那里读完，再从缓冲区 2 那里读。这样就不会撕裂也不会卡顿了啊~然而 这又出现一个 问题本来博尔牛寺 1/60 秒就把比赛跑完了， 显卡也把中间过程给渲染出来了，双重缓冲打开了之后，显示器从缓冲区 1 中读取第 0 秒的画面， 再从缓冲区 2 中读取第 1/120 秒的画面，再又回到缓冲区 1 中读取第 1/60 秒一共三张画面。显示器每 1/60 秒读取一张， 所以一共用时 3/60 秒。结果 就是博尔牛寺 活生生花了 3/60 秒才跑完，这就是所谓的 *「画面延迟」* 。

  - vblank间隙信息传送: 在垂直空白间隙中，显示器不会显示影像，影像讯号也不会被显示器给删除步。这一段时间对于设备来说是一个浪费，因此人们想了办法来利用 这一段时间， 电视台可以利用这一时间发送一些不可显示信息， 如果您使用 过图文电视您就会立刻明白，为什么图文电视卡要接收电视信号，电视卡可以解读这 一信息，而电视不能，这种信息就是利用垂直回扫期发送的，电视卡通过RS-232端口将接收到的不可显示 信息传送给计算机，由计算机加以处理， 这就是图文电 视的原理，也就是说，电视台利用垂直回扫期发送一些不可显示的信息，而图文电视卡将这种信息接收下来，经过解码发送到计算机内由计算机处理。

- Presentation模式是交换链配置中最重要的一个，因为它代表了呈现image到屏幕的条件。Vulkan中有4个可能的模式：
  - VK_PRESENT_MODE_IMMEDIATE_KHR ：俗称“立即渲染”，它只用一个framebuffer，渲染操作直接渲染到该缓冲，显示器刷新到来时直接从缓冲中取出 这张图像并显示。 由于显示和渲染是并行执行的，存在渲染未完成时就被显示器取走了， 导致取走的图像中一半是之前的结果，一半是这次未完全渲染的结果， 导致“图像撕裂”。渲染频率大于或小于vblank频率都会造成撕裂。
  - VK_PRESENT_MODE_FIFO_KHR：双重缓冲，垂直同步，交换链是一个队列，显示器刷新时，从队列头部拿一个image，程序将渲染好的image放到队列尾部。如果队列满了程序 必须等待。
  - VK_PRESENT_MODE_FIFO_RELAXED_KHR：只有当垂直回归结束后，app晚了，队列空了，这一模式才与上一个模式有所区别。它不等待下一次垂直回归，而是当image 到达 时立即传送。这可能导致可见的撕裂。
  - VK_PRESENT_MODE_MAILBOX_KHR：三重缓冲，第二个模式的另一变种。队列满时，它不阻塞app，队列中的image直接被新的替换。这个模式可被用于实现三重缓存，允许你避免撕裂，大幅减少延迟问题（与双缓存的垂直同步模式相比）


- 如果支持交换链，会涉及3个扩展：两种源于实例层，另一个就是作用于逻辑设备层的交换链扩展： *VK_KHR_swapchain* 
  - 第一种是在实例层定义的 *VK_KHR_surface* 扩展。 它描述“平面”对象，即应用窗口的逻辑表现形式。 该扩展支持我们查看平面的不同参数（功能、支持的格式、大小）， 并查询特定物理设备是否支持交换链 （更确切的说，特定队列家族 是否支持在特定平面上演示图像）。 这些信息非常实用，因为我们不想选择物理设备并尝试通过它创建 逻辑设备， 来了解它是否支持交换链。 该扩展还可定义破环此类平面的方法。
  - 第二种实例层扩展依赖于操作系统，*glfwgetrequiredinstanceextensionsll* 返回 *实例层* 用来创建surface的扩展列表，不但有基础的VK_KHR_surface扩展， 还有针对特定操作系统扩展：
    - Windows中称为 VK_KHR_win32_surface
    - Linux中称为 VK_KHR_xlib_surface 或 VK_KHR_xcb_surface
    - adnroid是 VK_KHR_android_surface
    - macOS是 VK_MVK_macos_surface
    - iOS是 VK_MVK_ios_surface

#+begin_src c++
 { // createSwapChain
     {// querySwapChainSupport(physicalDevice);  获取surface的 capabilities、formats、presentModes
         vkGetPhysicalDeviceSurfaceCapabilitiesKHR(gpu, surface, &details.capabilities); // 基础surface功能（交换链包含的image的最大\小数量，image的宽度和高度的最大\最小值）
         vkGetPhysicalDeviceSurfaceFormatsKHR(gpu, surface, &formatCount, details.formats.data()); // Surface格式（像素用32位表示VK_FORMAT_B8G8R8A8_UNORM、使用SRGB颜色空间 VK_COLOR_SPACE_SRGB_NONLINEAR_KHR
         vkGetPhysicalDeviceSurfacePresentModesKHR(gpu, surface, &presentModeCount, details.presentModes.data()); // 可用的presentation模式: VK_PRESENT_MODE_IMMEDIATE_KHR、FIFO、FIFO_RELAXED、MAILBOX
     }
     // if (availableFormat.format == VK_FORMAT_B8G8R8A8_UNORM && availableFormat.colorSpace == VK_COLOR_SPACE_SRGB_NONLINEAR_KHR)
     VkSurfaceFormatKHR surfaceFormat = chooseSwapSurfaceFormat(swapChainSupport.formats); // 像素格式和颜色空间：VK_FORMAT_B8G8R8A8_UNORM像素用32位表示。SRGB颜色空间VK_COLOR_SPACE_SRGB_NONLINEAR_KHR
     VkPresentModeKHR presentMode = chooseSwapPresentMode(swapChainSupport.presentModes); //  优先使用VK_PRESENT_MODE_MAILBOX_KHR 三重缓冲
     VkExtent2D extent = chooseSwapExtent(swapChainSupport.capabilities); // extent 是SwapChain中image的宽高，分辨率(resolution), 通常它与window的尺寸一样

     // VkSurfaceCapabilitiesKHR包含交换链渲染时允许的最大最小的image图像数量， image的宽高的最大/最小值
     uint32_t imageCount = swapChainSupport.capabilities.minImageCount + 1; // 交换链中有多少image。使用最小值，在请求另一个image渲染前，可能有时不得不等待driver完成内部操作。因此推荐至少比最小值多1

     swapchain_createInfo.minImageCount = imageCount; // 交换链至少提供多少个image, 推荐比capabilities的最小值多 1： capabilities.minImageCount + 1;
     swapchain_createInfo.imageFormat = surfaceFormat.format; // format指定颜色通道和存储类型，VK_FORMAT_B8G8R8A8_UNORM像素用32位表示
     swapchain_createInfo.imageColorSpace = surfaceFormat.colorSpace;  // colorSpace用来表示SRGB颜色空间是否被支持 VK_COLOR_SPACE_SRGB_NONLINEAR_KHR
     swapchain_createInfo.imageExtent = extent;
     swapchain_createInfo.imageArrayLayers = 1; // 表示image的层次，除非创建3D应用，否则这个值将为1.
     swapchain_createInfo.imageUsage = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT; // imageUsage指明Swap Chain里的image我们拿来做什么，在本例中将直接对image进行渲染，这就意味着Image将被当做颜色附件使用(color attachment)。如果你想先渲染一个单独的图片然后再进行处理，那就应该使用VK_IMAGE_USAGE_TRANSFER_DST_BIT并使用内存转换操作将渲染好的image 转换到SwapChain里。
     swapchain_createInfo.imageSharingMode = VK_SHARING_MODE_EXCLUSIVE; // VK_SHARING_MODE_EXCLUSIVE：一个image同一时间只能属于一个队列家族，所有权必须被显式地转移后，才能在另一个队列家族使用。这个选项提供最佳性能。

     swapchain_createInfo.preTransform = swapChainSupport.capabilities.currentTransform; // currentTransform说明交换链里的mage不需要变换。 如果surface支持变换如，90度或水平翻转，可以标明让它应用到交换链中的image
     swapchain_createInfo.compositeAlpha = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR; // 在和其它窗口混合的时候，忽略Alpha透明通道，
     swapchain_createInfo.presentMode = presentMode;
     swapchain_createInfo.clipped = VK_TRUE;    // 不处理那些被遮挡的部分， 可以得到更好的性能
     swapchain_createInfo.oldSwapchain = VK_NULL_HANDLE; // 窗口大小改变时，交换链会失效，需要重新创建. 这里要明确的指向旧的交换链。

     vkCreateSwapchainKHR(device, &createInfo, nullptr, &swapChain);
     vkGetSwapchainImagesKHR(device, swapChain, &imageCount, swapChainImages.data()); //  交换链在创建的过程中，也会自动创建至少minImageCount个VkImage。从交换链中获取已经创建的VkImage
#+end_src

*** VkImageView
- Vulkan编程模型里所有资源分为两种Buffer 和Image。Vulkan的函数里并没有Texture纹理这个词，取而代之的是Image和ImageView。
  - ImageView描述了如何访问Image以及访问图像的哪一部分，要在渲染管道中使用任何VkImage（包括交换链中的VkImage），必须创建一个VkImageView对象，也就是说Image不能直接使用，必须要通过ImageView。
  - Buffer和内存 & 数据传输
    - 创建Buffer之前都要先申请分配相应的内存，因为无论是Texture、VertexBuffer、IndexBuffer或者UniformBuffer等等，其实都最终都是一段内存，因此Vulkan将这些资源都视为Buffer。创建Buffer 时就需要指定 Buffer的大小、用途、共享模式等等。
    - 由于在GPU中需要内存对齐，因此Buffer大小与实际内存大小可能不一致。为了获取不同资源对应的内存对齐大小以及需要实际分配的内存大小，Vulkan提供了vkGetBufferMemoryRequirements函数。分配好内存之后，就可以将Buffer和内存绑定到一起。
    - 高速缓存具有最高的访问速度。其次就是访问各自独占的存储，而最慢的就是访问共享内存了，当然对于CPU来说访问共享内存与自己独占的内存在性能是基本没有差异的。这里的性能差异主要是从GPU的角度来说的。因此我们肯定愿意将一些CPU或GPU专有 的数据首先考虑放在各自的独占存储中，其次需要多方来访问的数据就放在共享内存中。
    - 说了这么废话，就是为了给数据传输做铺垫。对于UniformBuffer，我们可能更希望将它放置于共享内存中，对于Texture、Vertex、Index等我们更希望将它们放置于GPU的独立内存中。因此，对于UniformBuffer， 我们只需要在共享内存或者高速缓 存上面分配内存，绑定到Buffer。对于其它数据，我们则需要先在共享内存或者高速缓存上分配临时内存，绑定临时Buffer，然后将数据拷贝至于该块内存，最后则创建真正的Buffer以及在GPU上分配独立的内存，通过 Transfer Command将数据从共享 内存或者高速缓存拷贝至GPU内存。

- mipmap的基本思路是，对远处的东东，用尺寸较小、分辨率较低的纹理；对近处的东东，用尺寸交大、分辨率较高的纹理。 因为在三维世界中,显示一张图的大小与摄象机机距离模型的远近位置有关,近的地方,图片就大一些,远的地方图片就会小一些。 当摄像机较 远的时候，用精细的贴图玩家也看不见，而且还浪费资源，此时完全可以用更小的贴图。 mipmap先将贴图压缩成很多逐渐缩小的图片, 按照2的倍数进行缩小直到1X1， 把缩小的图都存储起来。例如一张64*64的图片,会产生64*64, 32*32,16*16,8*8,4*4, 2*2,1*1的7张图片,当屏幕上 需要绘制像素点 为20*20 时，程序只是利用 32*32 和 16*16 这两张图片来计算出即将显示为 20*20 大小的一个图片，这比单独利用 32*32 的那张原始片计算出来的图片效果要好得多，速度也更快.
  - mip level： 一系列缩略图的编号即为mip level。level 0 为原图，之后的每一个level 都比上一个level长宽缩减到一半，也就是按照2的倍数进行缩小直到1X1。Mip层0是最初的图像，之后的mip层被称为mip链。
    #+begin_src  c++
{ //createImageViews   - ImageView描述了如何访问Image以及访问图像的哪一部分，要在渲染管道中使用任何VkImage（包括交换链中的VkImage），必须创建一个VkImageView对象。
    for (size_t i = 0; i < swapChainImages.size(); i++) { //  为交换链中每个图像创建一个ImageView
        VkImageViewCreateInfo createInfo = {};
        createInfo.image = swapChainImages[i];
        createInfo.viewType = VK_IMAGE_VIEW_TYPE_2D; // 将图像视为1D纹理，2D纹理，3D纹理 、立方体贴图
        createInfo.format = swapChainImageFormat;    // VK_FORMAT_B8G8R8A8_UNORM
        createInfo.components.r = VK_COMPONENT_SWIZZLE_IDENTITY; // components允许你将颜色通道混合起来，比如，将所有通道都映射到红色通道，形成单色材质。我们这里用默认映射
        createInfo.components.g = VK_COMPONENT_SWIZZLE_IDENTITY;
        createInfo.components.b = VK_COMPONENT_SWIZZLE_IDENTITY;
        createInfo.components.a = VK_COMPONENT_SWIZZLE_IDENTITY;
        createInfo.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT; // subresourceRange描述图像用途以及哪些部分能被访问，我们的图像被用作颜色目标，不用任何mipmap层级
        createInfo.subresourceRange.baseMipLevel = 0;    // 一系列mipmap缩略图的编号即为 mip level。level 0为原图, 之后的每一个level 都比上一个level长宽缩减到一半
        createInfo.subresourceRange.levelCount = 1;
        createInfo.subresourceRange.baseArrayLayer = 0;
        createInfo.subresourceRange.layerCount = 1; // 如果开发3D应用，那么要创建具有多层的交换链。然后你可以为每个图像创建多个图像视图，通过访问不同的层来表示左右眼的视图

        vkCreateImageView(device, &createInfo, nullptr, &swapChainImageViews[i]);
    }
}
    #+end_src


** VkFrameBuffer
- Framebuffer 其实就是一堆VkImageView，framebuffer引用imageView ，把它当做color、depth和stencil的目标使用。因为swapchain里可以有多个image。framebuffer的创建个数需要跟swapchain里image的数量对应.


** 图像管线Graphics pipeline ->
- 图形渲染管线可以被划分为两个主要部分：
  1、把你的3D坐标转换为2D坐标。
  2、把2D坐标转变为实际的有颜色的像素。
- 顶点着色器: 最重要的功能是执行顶点的坐标变换和逐顶点光照。顶点坐标由局部坐标转换到 *归一化设备坐标NDC* 的运算，就是在这里发生的。通过坐标变换改变顶点位置可以实现很多酷炫的shader效果，如模拟水面，布料等等。顶点着色器的另一功能 是向后续 阶段的片段着色器提供一组易变（Varying）变量，用于插值计算。顶点着色器是逐顶点运算的程序，也就是说每个顶点数据都会执行一次，而且是独立的被执行，顶点着色器运算过程中无法访问其他顶点数据。当然各顶点彼此间是并行执行的。
- 片段着色器：计算每个片段（像素）的颜色值。同时，在这阶段片段着色器通常会要求输入纹理，从而对每个片段进行着色贴图。
        
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:vulkan_pipeline.png]]

- Vulkan的图形管线则基本是完全不能改变的，所以如果你想修改着色器，绑定不同帧缓冲或者改变混合函数，就要从头创建一个新的管线。缺点是你必须创建很多管线，代表所有你想要的不同的组合状态。但是由于你的操作都是预先知道的，驱动能很好地进行优化。
- SPIR-V是Vulkan着色器代码Shader的格式， 它是字节码格式，不是GLSL和HLSL这些人类可读的语法。SPIR-V可用于Vulkan和OpenCL，用来编写图形和计算着色器。我们不需要自己写字节码，LunarG SDK包含将GLSL编译到SPIR-V的程序glslangValidator

  
** Vulkan坐标和投影
*** Vulkna坐标
- NDC(Normalized Device Coordinates) 设备空间或标准化设备坐标：无论引擎中的坐标系是如何，有没有使用到世界空间、相机空间、投影空间等等，最终我们都需要统一到NDC这个坐标系下，这个坐标系也可以理解为应用程序与GPU的接口。
- Vulkan的NDC坐标：（-1，-1）位于左上角，（1，1）在右下角， 原点（0，0）在屏幕中心；也就是x轴正向朝右， y轴正向朝下, Z轴正向指向屏幕里面。

[[file:vulkan_ndc.png]]

- 齐次坐标系 Homogeneous Coordinates： 使我们能用同一个公式对点和方向作运算。向量的w分量也叫齐次坐标。想要从齐次向量得到3D向量，我们可以把x、y和z坐标分别除以w坐标。我们通常不会注意这个问题，因为w分量通常是1。
- 齐次之名: 如果我们要将欧式坐标的一个二维点 (1,2) 转换为齐次坐标，根据规则，我们可以选择 (1,2,1)，也可以选择 (2,4,2)，还可以选择 (4,8,4),(8,16,8)...，即 (k,2k,k),k∈ℝ 都是“合法”的齐次坐标表示，这些点都映射到 欧式空间中的一点，即这些点具有 尺度不变性（Scale Invariant），是“齐性的”(同族的)，所以称之为齐次坐标。
  1、若w==1，则向量(x, y, z, 1)为空间中的点。
  2、若w==0，则向量(x, y, z, 0)为方向。方向向量不能平移, 因为平移一个方向毫无意义。

- 局部坐标Local:  就是以物体的中心为坐标原点，物体的旋转或平移等操作都是围绕局部坐标系进行，当物体进行旋转或平移等操作时，局部坐标系也执行相应的旋转或平移操作。要注意的是，如果对物体进行缩放操作，则局部坐标系也要进行相应的缩放，如果 缩放比例在各坐标轴上不同，那么再经过旋转操作后，局部坐标轴之间可能不再相互垂直。无论是在世界坐标中进行转换还是在局部坐标中进行转换，程序代码是相同的，只是不同的坐标系考虑的转换方式不同罢了。一个物体的本地坐标经过一个model变换（缩放、旋转、平移），可以变换到世界坐标

- 世界坐标World :  世界坐标是始终固定不变的，它以屏幕中心为原点(0, 0, 0)。局部坐标只是相对于一个模型的，当我们想在屏幕上看到多个模型时，如果我们以某个模型所在的局部坐标系为基准去构造其他模型，那么就很有可能会出现所有的模型都叠放 在了原点。所以， 世界坐标用来确定每个模型在三维空 间中的位置。通常需要一个观察矩阵View Matrix将世界坐标转换到观察空间。

- 观察坐标View。在同一个世界坐标系内的各个3D对象共同组成了一个场景，对于这个场景，我们可以从不同的角度去观察，看到的也不同。因此观察空间就是从相机的角度来解释世界坐标系中的位置，它以摄像机的视角作为原点，把所有的世界坐标变换为相对于 摄像机位置与方向的观察坐标。观察空间用投影矩阵Projection Matrix执行一个投影变换就变成了裁剪空间，投影变换是从3D变换到2D的关键步骤。

- 裁剪坐标Clip:  我们通过一个屏幕来观察3D场景，屏幕不是无限大的，因此存在某些观察视角，我们看不到场景的全部。看不到的场景部分，就是通过这一步被裁剪掉的，这也是「裁剪」一词的来历；裁剪空间的可见部分，其实就是由投影矩阵定义的三维空间， 也叫 视椎体frustum。正射投影时是一个长方体，透视投影时是一个被削头的四凌锥体。另一方面，把3D场景投射到2D屏幕上，也主要是由这一步完成。另外，经过裁剪变换，3D对象的顶点个数不一定总是减少，还有可能被裁剪后反而增多了。裁剪是通过投影来完成的， 观察坐标经过投影变换后，就成了裁剪坐标。 裁剪坐标再经过透视除法perspective division，就会变成归一化设备坐标NDC。这个过程是自动进行的，我们不需要针对它来编程，因此我们经常把它和投影变换放在一起来理解。 我们可以不太严谨地暂且认为 ，相机坐标经过了一个投影变换，就直接得到NDC了。

- 归一化设备坐标NDC(Normalized Device Coordinate):  也就是vertex shader 里面gl_Position 中所处的坐标系。每个顶点的x，y，z坐标值在-1.0到1.0之间，超出这个坐标范围的顶点都将不可见。有时为了方便，我们自己 会设定一个坐标范围， 之后再在顶点着色器中将这些坐标变换为归一化设备坐标。虽然NDC包含x、y、z三个坐标轴，但它主要表达了顶点在xy平面内的位置，x和y坐标最终会对应到屏幕的像素位置上去。而z坐标只是为了表明深度关系，谁在前谁在后（前面的挡住后面的），因此z坐标 只是相对大小有意义，z的绝对数值是多大并不具有现实的意义。

- 屏幕坐标screen：NDC坐标每个维度的取值范围都是[-1,1]，但屏幕坐标大小不一。以分辨率720x1280的屏幕为例，它的x取值范围是[0, 720]，y的取值范围是[0,1280]。这样NDC坐标就需要一个变换，才能变换到屏幕坐标，这个变换就是视口变换(viewport transform)，它是自动完成的，但需要我们通过glViewport接口来指定绘制视口（屏幕）的大小。屏幕坐标与屏幕的像素(pixel)还不一样。屏幕坐标是屏幕上任意一个点的精确位置，可以是任意小数，但像素的位置只能是整数，是这个点的近似值。这里的视口 变换是从NDC坐标变换到屏幕坐标，还没有到最终的像素位置。后面还要通过光栅化Rasterization，把图元映射为屏幕上的像素，生成供片段着色器使用的片段。

*** 投影&矩阵
当我们观察3D世界的时候，是通过一块2D的屏幕，我们真正看到的实际是3D世界在屏幕上的一个投影。坐标变换就是要解决在给定的观察视角下，3D世界的每个点最终对应到2D屏幕上的哪个像素。投影： 可以理解成是一个空间的降维过程，例如从四维空间 投影到三维空间中。虽然投影矩阵的名称包含了投影二字，但是它并没有进行真正的投影工作，而是在为投影做准备。真正的投影发生在后面的透视除法或者叫齐次除法(homogeneous division)的过程中。而经过投影矩阵的变换后，顶点的w分量将会具有特殊的意义。

设想一下在3维空间里的一个3D模型，它必然拥有一些顶点信息，设其中任意顶点的坐标为(x,y,z,1), 后面的1是齐次坐标的意思。当我们需要把这个模型投影到某个平面上时，它就从3维变成了2维，而顶点坐标(x,y,z,1)则变成(x,y,d,?)。可以注意到， 经过透视变换后的顶点，依然是四维的形式，只是含义变了，其中的(x,y)分量指的是这个顶点在投影平面上的坐标。d指的是这个投影点的深度(depth)，d一般是规范化的，范围是[-1,1]。d的作用在下一个渲染阶段(Depth Test)大有用处。

- 模型矩阵(Model Matrix)：通过模型变换：缩放、旋转、平移，将模型由局部空间转换到世界空间。
- 观察矩阵(View Matrix)：摄像机/观察者的位置等信息，将所有世界坐标转换为观察坐标 。
- 投影矩阵(Projection Matrix)：这个投影变换，是从3D变换到2D的关键步骤。将观察坐标转换为裁剪坐标。

- 投影除法Projection divition： 把裁剪坐标变成NDC归一化设备坐标。
- 视口变换viewport transform：把NDC坐标变成屏幕坐标。

- 相机始终位于原点，相机坐标的Z轴方向与观察方向正好相反，也就是说相机或眼睛看向 Z 轴的负方向。为了实现移动相机的观察效果，一般的实现方式都是以相反的方式来调整场景中物体。
- 在欧式空间里，两条共面的平行线无法相交，然而在投影空间Projective Space内却不是这样，一个感性的理解是，如下图中的两条铁轨的间距随着视线变远而减小，直至在地平线处（无限远点）相交

- Perspective projection 透视投影：投影线相交于一点，因此投影的结果与原物体的实际大小并不一致，而是会近大远小。因此透视投影更接近于真实世界的投影方式。
- Orthographic projection 正交投影：平行投影的一种特殊情形，正交投影的投影线垂直于观察平面。平行投影的投影线相互平行，投影的结果与原物体的大小相等，广泛地用于工程制图。

- Frustum 视锥体(截椎体)的形状酷似一个塔尖被削平了的金字塔,更准确地说，是一个去掉头部的四棱锥体。事实上，视锥体本身由6个面所组成：近截面、远截面、上截面、下截面、左截面、右截面。处于这个视锥体里的对象，才是“可见”的对象，可见的对象 会被渲染到“视平面”上（三维到二维的投影）。视平面可以认为是视椎体的near面，对应着最终要投影的2D屏幕；far面相对来说没那么重要，因为人眼的视椎体是没有far面的（比如裸眼可以看到月亮星星，far面其实是无限远的）。在图像学中，far面用于将离相机太远的物体裁剪掉。 提高渲染效率。视锥体有4个参数：
  - 屏幕宽高比aspect ratio，简称ar = 视平面width/视平面height，其实就是视平面的宽高比
  - 垂直视野(vertical）field of view，简称fov，相机看向3d世界的垂直方向上的角度。
  - 近截面near Z Plane，简称near面，是一个平行于xy平面的面，对应着最终要投影的2D屏幕，用于将离相机太近的物体裁剪掉。
  - 远截面far Z Plane，简称far面， 用于将离相机太远的物体裁剪掉。


- 视锥剔除Frustum Culling非常的快(如果算法好的话)，而且是在渲染管线(Rendering Pipeline)之前进行的，不像背面剔除Backface Culling那样需要在渲染管线之后一个顶点一个顶点地计算。对于被剪裁掉的物体绘图引擎都不会将其送入显卡，因此视锥剔除对渲染速度有巨大的改善,毕竟什么都不渲染是最快的渲染.

** 创建渲染通道 Render pass，它标明渲染目标和用法
- render layer 是把不同的物体放到不同的 layer 层里去渲染，比如前景放到一层，背景放到一层，所以每个层里渲染出来的图像包括的物体的所有信息。比如物体的高光，颜色，反光，阴影等等都在一个层里。
- render passes.是指把一个物体的所有信息，分开来进行渲染，比如颜色 pass、高光 passes、环境光遮挡等等其他 passes。为什么我们要用不同的 pass 来渲染呢？在源头就将这些信息独立开来，这样在合成的时候我们就可以有更多的控制空间和选择余地了。

- Render pass 描述了在渲染阶段要使用的 image 类型、如何使用以及如何处理 image 的内容。请注意，Render pass 只是描述要使用的 image 类型，而 framebuffer( 通过绑定 image )才是要使用的 image 实体。
- VkRenderPass 由多个子 pass 组成。在简单的场景一般只有一个子 pass。子 pass 选择一些 attachment 作为颜色目标，另外一些作为深度和模版目标。如果你有多个子 pass，每个子 pass 将有不同的集合，一些用于输入，一些用于输出。

** 创建帧缓存，它引用渲染通道
color attachment 为从 swap chain 获取的 image，depth/stencil attachment 为 depth buffer 的 image。

** 构建图形管线 Graphics pipeline
#+ATTR_latex: :width 800   #+ATTR_HTML: :width 800  #+ATTR_ORG: :width 800
[[file:vulkan_pipeline.png]]

- Graphics Pipeline 通过创建 VkPipeline 对象来建立。它描述了一些显卡 *不可编程部分* 的可配置状态(configurable state )，比如 viewport 的大小和 depth buffer 操作等，以及用 *VkShaderModule 表示的可编程部分* 。VkShaderModule 对象用着色器的字节码来创建。驱动需要知道哪些渲染目标将在 pipeline 中使用，而这些目标就是我们在 Render pass 中定义的 image。

- Vulkan 和现存的其他图形 API 最显著地区别就是：几乎所有不可编程部分的配置都要在 pipeline 创建前提前完成。这就意味着如果你想换一个着色器(shader)或者仅仅改变一些顶点的布局(vertex layout) ,那么你必须重新创建 pipeline 。这也意味着你必须提前创建很多 pipeline，来应对渲染过程中不同组合的配置。只有很少的一些配置你可以动态改变，比如 viewport 的大小和 celar 的颜色等。Pipeline 中所有的配置状态你必须显示的进行定义，比如，颜色混合就没有为你提供默认的配置。

** 申请命令缓存，为交换链的每个 image 记录绘制命令
- Vulkan中的命令要先记录到VkCommandBuffer中，然后才能提交到队列queue，由队列将这些作业提交给物理设备去执行。VkCommandBuffer并不是直接创建的，它的构建非常昂贵， 它从VkCommandPool 中分配出来。
- 创建 *Command Buffer* 的三个重要元素分别为 VkDescriptorSet（纹理和常量）、VkPipeline（着色器和状态）和VkBuffer（顶点数组）

** 渲染一帧：请求 image，提交正确的绘制命令缓存，将 image 返回到交换链


* example code
#+begin_src c++
vkEnumerateInstanceExtensionProperties(nullptr, &extensionCount, extensions.data()); // 创建实例前，先获取所有可以用于实例的扩展， 确认所有想要的扩展都是存在的。 然后再在VkInstanceCreateInfo中请求启用。
vkEnumerateInstanceLayerProperties(&layerCount, availableLayers.data()); // 创建实例前，获得所有可用实例层的验证, 确认所有想要的验证都是存在的， 再在VkInstanceCreateInfo中请求启用。 常用的是：VK_LAYER_KHRONOS_validation， 检查看看它是否存在， 它是一个大的验证层集合， 系统把所 有标准常用的验证层都融合在一起。
// getRequiredExtensions
glfwGetRequiredInstanceExtensions(&glfwExtensionCount); //  返回实例层用来创建surface的扩展列表，不但有基础的 VK_KHR_surface扩展， 还有针对特定操作系统扩展， macOS是 VK_MVK_macos_surface

// 实例层验证VK_LAYER_KHRONOS_validation默认在终端输出所有验证信息。可以启用实例扩展VK_EXT_debug_utils，然后自定义一个回调函数，就可只输出我们感兴趣的信息。
instance_createInfo.ppEnabledExtensionNames = extensions.data(); // 包含3个扩展 VK_KHR_surface, VK_MVK_macos_surface,  VK_EXT_debug_utils
instance_createInfo.ppEnabledLayerNames = validationLayers.data(); // VK_LAYER_KHRONOS_validation, 它是一个大的验证层集合，系统把所有标准常用的验证层，都融合在一起。
populateDebugMessengerCreateInfo(debugmsg_CreateInfo);  // 设置接收消息的回调函数pfnUserCallback，要输出的信息类型：warning, error...触发回调的事件类型：validation, performance...
instance_createInfo.pNext = (VkDebugUtilsMessengerCreateInfoEXT*) &debugmsg_CreateInfo; // 把pNext设为debugmsg_CreateInfo，vkCreateDebugUtilsMessengerEXT和 vkDestroyDebugUtilsMessengerEXT 就可共用下面的debugMessenger实例。
vkCreateInstance(&createInfo, nullptr, &instance) // 创建实例，实例层扩展和验证，要在VkInstanceCreateInfo实例创建信息中请求启用。

// setupDebugMessenger   生成函数vkCreateDebugUtilsMessengerEXT 和 vkDestroyDebugUtilsMessengerEXT 共用的VkDebugUtilsMessengerEXT实例
VkDebugUtilsMessengerEXT debugMessenger;
vkCreateDebugUtilsMessengerEXT(instance, &debugmsg_CreateInfo, nullptr, &debugMessenger); // 生成VkDebugUtilsMessengerEXT的实例。

// createSurface, 创建surface 需要在 instance 被创建后立即被创建，因为它实际上会影响物理设备的选择。
glfwCreateWindowSurface(instance, window, nullptr, &surface);

{// pickPhysicalDevice

    vkEnumeratePhysicalDevices(instance, &deviceCount, gpus.data()); // 枚举GPU
    { // isDeviceSuitable
        {
            vkGetPhysicalDeviceProperties(gup, &gpuProperties); // 查询物理设备的属性：支持的Vulkan API版本、设备名称和类型（集成或专用/独立GPU）、厂商ID和限制。
            vkGetPhysicalDeviceFeatures(gpu, &gpuFeatures); // 获取物理设备的可选特性，如：是否支持geometryShaderh或者tessellationShader，纹理压缩、64位浮点数和多视口渲染
            if(gpuProperties.deviceType == VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU && gpuFeatures.geometryShader);  // 是否独立显卡和支持几何着色器

            // findQueueFamilies,  为了要在窗口中显示图片，队列就要支持绘制和呈现，也就是：VK_QUEUE_GRAPHICS_BIT  和 vkGetPhysicalDeviceSurfaceSupportKHR
            vkGetPhysicalDeviceQueueFamilyProperties(gpu, &queueFamilyCount, queueFamilies.data());  //获取物理设备的 队列属性
            if (queueFamily.queueCount > 0 && queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT);  // 现在我们将只查找支持图形命令的队列
            vkGetPhysicalDeviceSurfaceSupportKHR(gpu, i, surface, &presentSupport); // 以某个物理设备，的某个队列家族索引和surface为参数。 判断某个gpu、的某个队列家族、是否支持在这个surface显示present图像。
        }

        //checkDeviceExtensionSupport 获取莫个物理设备的所有 *逻辑设备扩展* 确认支持交换链扩展VK_KHR_swapchain， 要显示图片，这个逻辑设备扩展一定要
        vkEnumerateDeviceExtensionProperties(gpu, nullptr, &extensionCount, availableExtensions.data());

        { // querySwapChainSupport   //获取surface的 capabilities、formats、presentModes
            vkGetPhysicalDeviceSurfaceCapabilitiesKHR(gpu, surface, &details.capabilities); // 基础surface功能（交换链包含的image的最大\小数量，image的宽度和高度的最大\最小值）
            vkGetPhysicalDeviceSurfaceFormatsKHR(gpu, surface, &formatCount, details.formats.data()); // Surface格式（像素格式，颜色空间）
            vkGetPhysicalDeviceSurfacePresentModesKHR(gpu, surface, &presentModeCount, details.presentModes.data()); // 可用的presentation模式
        }
    }}

{// createLogicalDevice
    queueCreateInfo.queueFamilyIndex = selected_queuefamily_index;  // 想要启用的队列家族索引（通过它创建队列）, 队列在设备创建时会一同自动创建。
    queueCreateInfo.queueCount = 1; //我们希望在特定队列家族中启用的队列数量
    device_createInfo.pQueueCreateInfos = queueCreateInfos.data();
    createInfo.pEnabledFeatures = &deviceFeatures; // 希望启用的 vkGetPhysicalDeviceFeatures 特性， 比如几何着色器。

    device_createInfo.ppEnabledExtensionNames = deviceExtensions.data(); //启用逻辑设备交换链扩展VK_KHR_swapchain，显示图片这个一定要。deviceExtensions = { VK_KHR_SWAPCHAIN_EXTENSION_NAME }
    vkCreateDevice(gpu, &device_createInfo, nullptr, &device);  // 队列随着逻辑设备的创建而自动创建

    vkGetDeviceQueue(device, indices.graphicsFamily.value(), 0, &graphicsQueue); // 从队列家族获取队列句柄，保存在graphicsQueue。因为我们只创建一个队列，用索引0即可。
    vkGetDeviceQueue(device, indices.presentFamily.value(), 0, &presentQueue);
}

{ // createSwapChain 
    {// querySwapChainSupport(physicalDevice);  获取surface的 capabilities、formats、presentModes
        vkGetPhysicalDeviceSurfaceCapabilitiesKHR(gpu, surface, &details.capabilities); // 基础surface功能（交换链包含的image的最大\小数量，image的宽度和高度的最大\最小值）
        vkGetPhysicalDeviceSurfaceFormatsKHR(gpu, surface, &formatCount, details.formats.data()); // Surface格式（像素用32位表示VK_FORMAT_B8G8R8A8_UNORM、使用SRGB颜色空间 VK_COLOR_SPACE_SRGB_NONLINEAR_KHR
        vkGetPhysicalDeviceSurfacePresentModesKHR(gpu, surface, &presentModeCount, details.presentModes.data()); // 可用的presentation模式: VK_PRESENT_MODE_IMMEDIATE_KHR、FIFO、FIFO_RELAXED、MAILBOX
    }
    // if (availableFormat.format == VK_FORMAT_B8G8R8A8_UNORM && availableFormat.colorSpace == VK_COLOR_SPACE_SRGB_NONLINEAR_KHR)
    VkSurfaceFormatKHR surfaceFormat = chooseSwapSurfaceFormat(swapChainSupport.formats); // 像素格式和颜色空间：VK_FORMAT_B8G8R8A8_UNORM像素用32位表示。SRGB颜色空间VK_COLOR_SPACE_SRGB_NONLINEAR_KHR
    VkPresentModeKHR presentMode = chooseSwapPresentMode(swapChainSupport.presentModes); //  优先使用VK_PRESENT_MODE_MAILBOX_KHR 三重缓冲
    VkExtent2D extent = chooseSwapExtent(swapChainSupport.capabilities); // extent 是SwapChain中image的宽高，分辨率(resolution), 通常它与window的尺寸一样

    // VkSurfaceCapabilitiesKHR包含交换链渲染时允许的最大最小的image图像数量， image的宽高的最大/最小值
    uint32_t imageCount = swapChainSupport.capabilities.minImageCount + 1; // 交换链中有多少image。使用最小值，在请求另一个image渲染前，可能有时不得不等待driver完成内部操作。因此推荐至少比最小值多1

    swapchain_createInfo.minImageCount = imageCount; // 交换链至少提供多少个image, 推荐比capabilities的最小值多 1： capabilities.minImageCount + 1;
    swapchain_createInfo.imageFormat = surfaceFormat.format; // format指定颜色通道和存储类型，VK_FORMAT_B8G8R8A8_UNORM像素用32位表示
    swapchain_createInfo.imageColorSpace = surfaceFormat.colorSpace;  // colorSpace用来表示SRGB颜色空间是否被支持 VK_COLOR_SPACE_SRGB_NONLINEAR_KHR
    swapchain_createInfo.imageExtent = extent;
    swapchain_createInfo.imageArrayLayers = 1; // 表示image的层次，除非创建3D应用，否则这个值将为1.
    swapchain_createInfo.imageUsage = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT; // imageUsage指明Swap Chain里的image我们拿来做什么，在本例中将直接对image进行渲染，这就意味着Image将被当做颜色附件使用(color attachment)。如果你想先渲染一个单独的图片然后再进行处理，那就应该使用VK_IMAGE_USAGE_TRANSFER_DST_BIT并使用内存转换操作将渲染好的image 转换到SwapChain里。
    swapchain_createInfo.imageSharingMode = VK_SHARING_MODE_EXCLUSIVE; // VK_SHARING_MODE_EXCLUSIVE：一个image同一时间只能属于一个队列家族，所有权必须被显式地转移后，才能在另一个队列家族使用。这个选项提供最佳性能。

    swapchain_createInfo.preTransform = swapChainSupport.capabilities.currentTransform; // currentTransform说明交换链里的mage不需要变换。 如果surface支持变换如，90度或水平翻转，可以标明让它应用到交换链中的image
    swapchain_createInfo.compositeAlpha = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR; // 在和其它窗口混合的时候，忽略Alpha透明通道，
    swapchain_createInfo.presentMode = presentMode;
    swapchain_createInfo.clipped = VK_TRUE;    // 不处理那些被遮挡的部分， 可以得到更好的性能
    swapchain_createInfo.oldSwapchain = VK_NULL_HANDLE; // 窗口大小改变时，交换链会失效，需要重新创建. 这里要明确的指向旧的交换链。

    vkCreateSwapchainKHR(device, &createInfo, nullptr, &swapChain);
    vkGetSwapchainImagesKHR(device, swapChain, &imageCount, swapChainImages.data()); //  交换链在创建的过程中，也会自动创建至少minImageCount个VkImage。从交换链中获取已经创建的VkImage
}

{ //createImageViews   - ImageView描述了如何访问Image以及访问图像的哪一部分，要在渲染管道中使用任何VkImage（包括交换链中的VkImage），必须创建一个VkImageView对象。
    for (size_t i = 0; i < swapChainImages.size(); i++) { //  为交换链中每个图像创建一个ImageView
        VkImageViewCreateInfo createInfo = {};
        createInfo.image = swapChainImages[i];
        createInfo.viewType = VK_IMAGE_VIEW_TYPE_2D; // 将图像视为1D纹理，2D纹理，3D纹理 、立方体贴图
        createInfo.format = swapChainImageFormat;    // VK_FORMAT_B8G8R8A8_UNORM
        createInfo.components.r = VK_COMPONENT_SWIZZLE_IDENTITY; // components允许你将颜色通道混合起来，比如，将所有通道都映射到红色通道，形成单色材质。我们这里用默认映射
        createInfo.components.g = VK_COMPONENT_SWIZZLE_IDENTITY;
        createInfo.components.b = VK_COMPONENT_SWIZZLE_IDENTITY;
        createInfo.components.a = VK_COMPONENT_SWIZZLE_IDENTITY;
        createInfo.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT; // subresourceRange描述图像用途以及哪些部分能被访问，我们的图像被用作颜色目标，不用任何mipmap层级
        createInfo.subresourceRange.baseMipLevel = 0;    // 一系列mipmap缩略图的编号即为 mip level。level 0为原图, 之后的每一个level 都比上一个level长宽缩减到一半
        createInfo.subresourceRange.levelCount = 1;
        createInfo.subresourceRange.baseArrayLayer = 0;
        createInfo.subresourceRange.layerCount = 1; // 如果开发3D应用，那么要创建具有多层的交换链。然后你可以为每个图像创建多个图像视图，通过访问不同的层来表示左右眼的视图

        vkCreateImageView(device, &createInfo, nullptr, &swapChainImageViews[i]);
    }
}
#+end_src


* Vulkan 初始化流程 ：

1) vkCreateInstance()： VkInstanceCreateInfo +  VkApplicationInfo  创建实例
2) vkCreateDebugUtilsMessengerEXT：VK_LAYER_KHRONOS_validation默认在终端输出所有验证层的调试信息。启用实例扩展VK_EXT_debug_utils后， 自定义一个回调函数，输出我们感兴趣的信息。
3) glfwCreateWindowSurface：窗口 surface 需要在 instance 被创建后立即被创建，因为它实际上会影响物理设备的选择。

4) vkEnumeratePhysicalDevices() -> vkGetPhysicalDeviceQueueFamilyProperties() 根据合适的队列簇，选择物理设备, 为了要在窗口中显示图片，队列就要支持绘制和呈现，也就是：VK_QUEUE_GRAPHICS_BIT  和 vkGetPhysicalDeviceSurfaceSupportKHR
5) vkCreateDevice(): VkDeviceCreateInfo + VkDeviceQueueCreateInfo  创建逻辑设备、队列随着逻辑设备的创建而自动创建。

6) vkCreateSwapchainKHR()
7) vkCreateImageView(): 为了使用 VkImage,不管是在 SwapChain 还是在 Pipeline 中，都必须先创建 VkImageView, 它是 image 的一个 view，描述了我们如何访问 image、访问 image 的哪一部分等。
8) : vkCreateShaderModule() 在 Vulkan 中，图形管线几乎完全不允许进行动态设置，如果我们 想使用其它着色器，绑定其它帧缓冲，以及改变混合函数，都需要重新创 建管线。这就迫使我们必须提前创建所有我们需要使用的图形管线，虽然 这样看起来不太方便，但这给驱动程序带来了很大的优化空间。


#+ATTR_latex: :width 800
#+ATTR_HTML: :width 800
#+ATTR_ORG: :width 800
[[file:vulkan_pipeline.png]]


vkCreateInstance() → vkEnumeratePhysicalDevices() → vkCreateDevice()
vkEnumerateInstanceExtensionProperties()  // 为了在创建 instance 前检索支持的扩展 VkExtensionProperties

vkEnumerateInstanceLayerProperties 函数列出所有可以用的层
vkGetPhysicalDeviceFeatures
vkGetPhysicalDeviceProperties
vkGetPhysicalDeviceMemoryProperties


* 111111
** 222222
dkaiekdiekdei
**** 33333333
dafadsfasdf
ddadakdi

dakfaifei
:: djie
dkajie :: adkei
jdaie:: dsajie
aaa :: djaiedkei


***** 44444444
****** 55555555555555
******* 6666666666666
******** 7777777777777
********* 88888888888888
